{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkelcL8Mntj11Id/qhTshE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haja2611/dolly-with_git/blob/main/dolly_integrated_with_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd5ttORfn_ph"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "oUWoyDyJoEYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "jEICA6LFoG12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "OaJps0yDoGzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  GitPython"
      ],
      "metadata": {
        "id": "MLWilIc7oGxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community faiss-gpu"
      ],
      "metadata": {
        "id": "R9byXonFoGul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  transformers --quiet"
      ],
      "metadata": {
        "id": "hYva467iyyR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"accelerate>=0.16.0,<1\" \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\"\n"
      ],
      "metadata": {
        "id": "relV8DXZ7lz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "EfHvg7SVzdCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hf = HuggingFacePipeline.from_model_id(\n",
        "#     model_id=\"gpt2\",\n",
        "#     task=\"text-generation\",\n",
        "#     pipeline_kwargs={\"max_new_tokens\": 10},\n",
        "# )"
      ],
      "metadata": {
        "id": "XDRvjDrc5Ni9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "generate_text = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16,\n",
        "                         trust_remote_code=True, device_map=\"auto\", return_full_text=True)\n"
      ],
      "metadata": {
        "id": "pVc2A6Dr7xwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import PromptTemplate, LLMChain\n",
        "# from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# # template for an instrution with no input\n",
        "# # prompt = PromptTemplate(\n",
        "# #     input_variables=[\"instruction\"],\n",
        "# #     template=\"{instruction}\")\n",
        "\n",
        "# # template for an instruction with input\n",
        "# prompt_with_context = PromptTemplate(\n",
        "#     input_variables=[\"instruction\", \"context\"],\n",
        "#     template=\"{instruction}\\n\\nInput:\\n{context}\")\n",
        "\n",
        "# hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# # llm_chain = LLMChain(llm=hf_pipeline, prompt=prompt)\n",
        "# llm_context_chain = LLMChain(llm=hf_pipeline, prompt=prompt_with_context)\n"
      ],
      "metadata": {
        "id": "_zMf0lZ27xfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(llm_chain.predict(instruction=\"Explain to me the difference between nuclear fission and fusion.\").lstrip())\n"
      ],
      "metadata": {
        "id": "XeN53DI18voP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# context = \"\"\"George Washington (February 22, 1732[b] - December 14, 1799) was an American military officer, statesman,\n",
        "# and Founding Father who served as the first president of the United States from 1789 to 1797.\"\"\"\n",
        "\n",
        "# print(llm_context_chain.predict(instruction=\"When was George Washington president?\", context=context).lstrip())\n"
      ],
      "metadata": {
        "id": "FCjJH2078vL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.llms import GooglePalm\n",
        "\n",
        "# api_key = 'AIzaSyAPSGbHPjcEfgZJVH1_xyDjYXmtydGIkgg' # get this free api key from https://makersuite.google.com/\n",
        "\n",
        "# llm = GooglePalm(google_api_key=api_key, temperature=0.1)\n",
        "# print(llm)"
      ],
      "metadata": {
        "id": "MqEPGIrxoGsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "# from langchain.llms import GooglePalm"
      ],
      "metadata": {
        "id": "5TXHiCbKoGps"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceHubEmbeddings()"
      ],
      "metadata": {
        "id": "iU9FKnSaoGnc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import GitLoader"
      ],
      "metadata": {
        "id": "RHCCOI2moGk8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "sUoFZVH5PIxj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/haja2611/traffic-map\",\n",
        "    repo_path=\"/content/git_repo/test_repo1\",\n",
        "    branch=\"main\",\n",
        ")"
      ],
      "metadata": {
        "id": "VqAU5me1oGiV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "pRnBniIdoGf-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "9qwEjVacPOf7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLl6H7fwoGdm",
        "outputId": "8b29242d-cc33-4679-c944-72e9923bba3e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wur5SzNyoGbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed a query\n",
        "query = \"which api i used in this repo?\"\n",
        "# embedding = model.embed_query(query)\n",
        "query_result = embeddings.embed_query(query)\n",
        "print(\"Query Embedding:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyOfsIlRouxS",
        "outputId": "a33a048b-d28c-4f3b-c967-6db61bb19b4a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding: [0.05049009248614311, 0.04983653500676155, -0.022192923352122307, 0.012052188627421856, -0.03945688530802727, -0.005193249322474003, -0.009651761502027512, 0.043326932936906815, 0.03574671223759651, 0.0018413250800222158, -0.006058174651116133, 0.04653766751289368, 0.05168180912733078, 0.009673616848886013, 0.03658929839730263, 0.0554187074303627, -0.0039008266758173704, 0.008515818975865841, 0.041173260658979416, 0.01851631887257099, -0.020419051870703697, 0.030759021639823914, 0.002830794081091881, 0.05179373919963837, 0.05239516869187355, -0.021641360595822334, -0.023223476484417915, -0.019989890977740288, 0.002848884789273143, -0.003419184824451804, 0.0667477697134018, 0.04972518980503082, 0.028480613604187965, -0.004143793601542711, 1.6727259435356245e-06, -0.020102962851524353, 0.01075181644409895, 0.008397399447858334, 0.010185012593865395, -0.014741410501301289, -0.020110245794057846, 0.03741145879030228, 0.040033008903265, -0.020235951989889145, 0.031111476942896843, -0.030981294810771942, -0.023301895707845688, -0.013024638406932354, -0.0029925242997705936, 0.05688522756099701, 0.019364381209015846, -0.010264172218739986, 0.004833380226045847, 0.0022681215777993202, 0.028763100504875183, 0.013826820068061352, 0.015333078801631927, -0.009287865832448006, 0.02640978991985321, 0.024365259334445, 0.024357309564948082, -0.0077623226679861546, -0.03708858788013458, 0.01616067998111248, 0.022849224507808685, -0.004287393298000097, -0.006908906623721123, -0.1060597375035286, 0.005550964269787073, -0.019544636830687523, 0.009446556679904461, 0.050009094178676605, 0.01216934248805046, 0.09141077101230621, -0.05895410478115082, -0.028246542438864708, -0.009822632186114788, -0.015942225232720375, 0.0134927062317729, -0.038072485476732254, -0.0543774738907814, -0.010503056459128857, -0.021984251216053963, 0.004569621756672859, 0.009708678349852562, 0.06870443373918533, -0.02348095364868641, 0.054083436727523804, 0.024523423984646797, -0.019194167107343674, -0.07873903959989548, -0.04699385166168213, -0.035049375146627426, 0.012029305100440979, 0.044523686170578, -0.05726427212357521, 0.06693317741155624, -0.04160357639193535, 0.055248383432626724, 0.03971780464053154, -0.052368730306625366, 0.03207942098379135, -0.031606703996658325, -0.045986685901880264, 0.02430725283920765, 0.06409487128257751, 0.059993643313646317, 0.025082428008317947, 0.04884897544980049, 0.04468941316008568, 0.02205548621714115, 0.04491029307246208, 0.002750001149252057, 0.05433449149131775, 0.040311478078365326, -0.04327763244509697, 0.04142975062131882, -8.789392450125888e-05, 0.025644201785326004, 0.04384186863899231, -0.015422364696860313, -0.03569330647587776, -0.0171720739454031, -0.029580291360616684, -0.0011931960470974445, -0.035835158079862595, -0.006168116349726915, 0.0018763820407912135, 0.0209999680519104, -0.020647546276450157, -0.04036666825413704, -0.014488831162452698, -0.02451944164931774, -0.051788076758384705, 0.014736254699528217, 0.022277912124991417, 0.0012535839341580868, -0.0270376019179821, -0.040921617299318314, -0.02114061452448368, 0.04326028749346733, -0.012439247220754623, -0.0426492914557457, -0.05926429107785225, 0.009079186245799065, 0.03432365506887436, -0.00469981087371707, -0.024164605885744095, -0.010705539025366306, -0.0038790784310549498, -0.08961989730596542, -0.025127748027443886, -0.0444766990840435, 0.03050432726740837, -0.0018443656153976917, -0.0023746630176901817, -0.06924856454133987, 0.020176494494080544, -0.023049447685480118, 0.027020378038287163, 0.021144067868590355, -0.012861859984695911, 0.042575933039188385, -0.025937946513295174, 0.019817469641566277, 0.00045949406921863556, 0.061632003635168076, 0.017591949552297592, -0.02189272828400135, -0.004829843062907457, -0.011436588130891323, -0.0406901054084301, -0.024490874260663986, -0.008524177595973015, -0.0024124118499457836, 0.061434969305992126, 0.06357670575380325, -0.09860353916883469, -0.04673027619719505, 0.050925321877002716, 0.01546062808483839, -0.05641522258520126, -0.006793500855565071, -0.046921323984861374, -0.040646009147167206, -0.008987468667328358, -0.027543360367417336, 0.022348498925566673, 0.0013774533290416002, 0.015455922111868858, 0.005078285001218319, -0.032056380063295364, -0.11359377205371857, -0.03078419342637062, 0.028677133843302727, 0.011474473401904106, 0.032866716384887695, -0.029171818867325783, -0.0021343561820685863, 0.007862119004130363, -0.014476785436272621, -0.009514397010207176, 0.07085075229406357, -0.011948161758482456, 0.029236841946840286, -0.02553299255669117, 0.0013906683307141066, 0.0010110909352079034, 0.0014610507059842348, 0.05820763483643532, -0.04468788206577301, 0.012320778332650661, -0.0003948214871343225, 0.03683307021856308, -0.02057361789047718, -0.0019856186117976904, 0.0342014878988266, 0.01575179398059845, -0.01121783722192049, -0.009911597706377506, -0.03082302212715149, -0.005309747066348791, 0.021128572523593903, 0.009793269447982311, 0.009422066621482372, 0.023992974311113358, 0.02031426690518856, -0.0004999559605494142, -0.013891978189349174, -0.004990882705897093, 0.010852830484509468, -0.026766974478960037, -0.028585541993379593, 0.008623543195426464, 0.024497119709849358, 0.03589494526386261, 0.10895396769046783, 0.004972068127244711, 0.0249565988779068, 0.021653855219483376, 0.004294627346098423, 0.03676861524581909, -0.03744390234351158, 0.06270568072795868, 0.06654220074415207, 0.004379748832434416, 0.006185324862599373, 0.0004870860429946333, 0.016134731471538544, -0.03185358643531799, 0.07431282103061676, 0.024837693199515343, 0.028485246002674103, -0.04368419572710991, 0.024623237550258636, 0.007459535263478756, -0.013935282826423645, 0.011178223416209221, 0.008599315769970417, 0.021461939439177513, 0.05394870787858963, -0.06247391179203987, -0.0006788326427340508, -0.018169185146689415, -0.011056462302803993, 0.003985824529081583, -0.03621203824877739, 0.046373456716537476, 0.03917799890041351, -0.02661825716495514, -0.02606012113392353, -0.008866622112691402, 0.0024973058607429266, -0.01447903923690319, 0.010778560303151608, 0.06599589437246323, 0.014304294250905514, -0.05891512706875801, -0.02334662154316902, -0.027477601543068886, -0.0030793643090873957, 0.00022447892115451396, -0.034671127796173096, 0.023341182619333267, 0.022593526169657707, 0.06727024167776108, -0.021571533754467964, 0.018666742369532585, -0.04678618907928467, -0.11051155626773834, -0.02288435585796833, 0.007495311088860035, -0.020362066105008125, -0.07338982075452805, 0.0027793501503765583, 0.02673148736357689, -0.045800041407346725, -0.03062506578862667, -0.023749614134430885, -0.015243763104081154, -0.014317786321043968, 0.030193360522389412, -0.04825560376048088, 0.016928652301430702, -0.00787094421684742, -0.018143445253372192, 0.037212394177913666, -0.06599291414022446, 0.036528073251247406, -0.021954931318759918, 0.05106645077466965, 0.012536679394543171, -0.03804001212120056, -0.030773168429732323, 0.01523175835609436, -0.002475772751495242, 0.06229637563228607, 0.027618972584605217, 0.003004796337336302, 0.005728302523493767, 0.0024724930990487337, -0.03604213520884514, -0.03424067795276642, -0.014196783304214478, -0.029153531417250633, -0.015308616682887077, 0.03556910529732704, 0.03472137078642845, 0.022702055051922798, 0.03453364968299866, -0.006853842176496983, -0.04786413535475731, -0.057690706104040146, 0.05967423692345619, 0.05823583900928497, -0.01173586305230856, -0.025886207818984985, -0.003501106286421418, 0.0077477991580963135, 0.03118274360895157, 0.018173592165112495, 0.019947264343500137, 0.03347238153219223, -0.002977022435516119, -0.01268631312996149, -0.002482885494828224, -0.04987943917512894, 0.02137576974928379, -0.0007185988943092525, -0.007481839973479509, 0.003424359718337655, 0.07802939414978027, -0.0051093921065330505, 0.010514378547668457, -0.021494561806321144, -0.0656457468867302, 0.04913349449634552, 0.001413532067090273, -0.01047103013843298, 0.05067756399512291, -0.004779862239956856, -0.03571833297610283, 0.0788528248667717, 0.025426305830478668, -0.06684935837984085, -0.008074969984591007, 0.02335883304476738, -0.05228216201066971, 0.00435681501403451, 0.03383912518620491, -0.025054017081856728, 0.02265848219394684, 0.03209923207759857, 0.039642583578825, 0.017451507970690727, -0.08158833533525467, -0.0064568892121315, 0.01725132390856743, -0.04687805101275444, 0.01296581793576479, -0.009074414148926735, -0.06999734789133072, -0.010698766447603703, 0.01997898519039154, 0.019078025594353676, 0.005221331026405096, -0.026514923200011253, 0.008818881586194038, 0.04779417812824249, 0.009510609321296215, -0.0053350841626524925, -0.055984556674957275, -0.04568234086036682, -0.06358768790960312, 0.039004240185022354, -0.019482051953673363, -0.06961231678724289, -0.006658175028860569, 0.04884915053844452, 0.053947072476148605, -0.03988131880760193, 0.01658347249031067, 0.019584380090236664, 0.010279371403157711, -0.025336649268865585, 0.010487440973520279, 0.05804124101996422, 0.001996274571865797, 0.026358023285865784, 0.04488401487469673, 0.011118177324533463, -0.0052253869362175465, 0.0007657194510102272, -0.029476946219801903, 0.1092265322804451, -0.032066576182842255, 0.006995650939643383, 0.024252874776721, 0.03203684091567993, -0.12888194620609283, 0.027032002806663513, -0.04199013486504555, -0.016533637419342995, -0.007424608338624239, 0.03137766942381859, 0.020660359412431717, 0.07340822368860245, 0.018568076193332672, -0.00222043227404356, 0.00044445908861234784, 0.025322336703538895, -0.034049972891807556, -0.02917473390698433, 0.007208253722637892, -0.015592428855597973, -0.009685772471129894, 0.006316527724266052, 0.02316293492913246, -0.020142290741205215, -0.021805549040436745, 0.03840921074151993, -0.029768390581011772, -0.03586757183074951, 0.018901126459240913, 0.010650133714079857, 0.03040207549929619, -0.022378630936145782, 0.014063256792724133, -0.020223673433065414, 0.05822470411658287, 0.015011198818683624, -0.0229775570333004, -0.07444668561220169, 0.020777814090251923, 0.03741629421710968, -0.058276884257793427, 0.03264635428786278, -0.023309078067541122, -0.029650967568159103, -0.048547644168138504, 0.012785199098289013, 0.014530315063893795, 0.021017830818891525, -0.01734783686697483, 0.03830281272530556, -0.09816521406173706, 0.0355241633951664, -0.03750165179371834, -0.0110146664083004, -0.013056370429694653, 0.05334622040390968, -0.003948731813579798, 0.019426899030804634, -0.011399021372199059, -0.04929446429014206, 0.0061141629703342915, 0.0004170825704932213, 0.05772010609507561, 0.03954187408089638, -0.052425675094127655, -0.013246072456240654, 0.06171108037233353, 0.016963299363851547, -0.00393910426646471, 0.0031256508082151413, -0.0348731204867363, 0.0484156534075737, 0.0021387857850641012, -0.011640958487987518, -0.037209223955869675, -0.004466633778065443, -0.09573990851640701, 0.02133674919605255, 0.011100294068455696, 0.01730489358305931, 0.08668665587902069, -0.013439892791211605, -0.028835540637373924, 0.007084317039698362, 0.017631078138947487, -0.05538821965456009, -0.02942807599902153, 0.008330386132001877, 0.0016387809300795197, -0.03462926298379898, 0.027163509279489517, -0.019254498183727264, -0.022235916927456856, -0.02667081356048584, -0.055547136813402176, 0.035826828330755234, -0.02874617837369442, -0.02630840428173542, -0.0006788214668631554, 0.05472657456994057, 0.022916005924344063, 0.011534517630934715, -0.07118801772594452, 0.06807789206504822, 0.007806276436895132, 0.03277429938316345, -0.03591561317443848, 0.012657790444791317, 0.007576728705316782, 0.0014464400010183454, -0.05224388465285301, -0.029718555510044098, -0.03356338292360306, -0.058433596044778824, 0.09446576237678528, -0.05664283037185669, 0.04369086027145386, -0.059625983238220215, -0.03038789890706539, -0.026017678901553154, -0.031553056091070175, 0.04962281137704849, -0.011744261719286442, -0.04299996420741081, -0.02465149573981762, -0.008770382963120937, 0.04029392823576927, 0.012269929982721806, 0.021882982924580574, 0.031086556613445282, 0.07615059614181519, -0.0088370805606246, 0.02345534786581993, -0.0035326366778463125, -0.08029234409332275, -0.027318626642227173, -0.025966640561819077, -0.09449274092912674, 0.03937539458274841, -0.006164194084703922, -5.017610860796381e-33, -0.005894558969885111, -0.027796467766165733, -0.04313383251428604, 0.03472995385527611, 0.011699209921061993, 0.01538870669901371, -0.005221378989517689, -0.033414870500564575, -0.013054493814706802, -0.0695531815290451, 0.05766639858484268, -0.0037589394487440586, 0.0012605313677340746, -0.008428787812590599, 0.0045043244026601315, 0.05833740159869194, -0.053775034844875336, -0.04432399198412895, -0.01733103208243847, -0.03957580402493477, -0.017839796841144562, -0.00747318472713232, -0.032529011368751526, 0.026175225153565407, -0.04114898666739464, -0.01740814372897148, 0.025718873366713524, 0.03229398652911186, 0.020432138815522194, 0.0053647300228476524, 0.03503531962633133, -0.05340774357318878, -0.03636159002780914, 0.01297602429986, 0.004431090783327818, -0.05279913172125816, 0.026666199788451195, -0.04870881885290146, 0.0037509724497795105, 0.035052746534347534, -0.012397471815347672, -0.026242677122354507, 0.009114252403378487, -0.013006066903471947, -0.012986814603209496, -0.0732342004776001, -0.016977068036794662, -0.029812278226017952, -0.0016919034533202648, 0.09436705708503723, 0.024253590032458305, -0.013894050382077694, -0.0031725727021694183, 0.008081099949777126, 0.03812016174197197, 0.040172427892684937, 0.04413219541311264, 0.0719241052865982, -0.012603460811078548, -0.05359939485788345, 0.0020152817014604807, -0.006879359018057585, 0.023983225226402283, 0.020596100017428398, 0.0691588744521141, -0.02005951665341854, -0.008722495287656784, -0.04922492429614067, 0.021803198382258415, 0.08072904497385025, 0.014360349625349045, 0.03380391001701355, 0.044512614607810974, -0.030724577605724335, -0.08465896546840668, -0.05603113770484924, 0.03173014894127846, 0.027137817814946175, 0.016679521650075912, 0.018066808581352234, 0.034078557044267654, -0.053365711122751236, 0.022625356912612915, 0.03562971204519272, -0.020571714267134666, -0.06258728355169296, -0.033852718770504, -0.003052370622754097, -0.026972759515047073, -0.01221462618559599, 0.07355010509490967, 0.018539000302553177, -0.012383799068629742, -0.028337452560663223, 0.044788677245378494, -0.010902035981416702, -0.07719550281763077, 0.030423887073993683, 0.010323450900614262, -0.041830193251371384, 0.028219815343618393, 0.003689885139465332, 0.021002566441893578, -0.030322276055812836, 0.02411208488047123, 0.012747544795274734, 0.015970010310411453, -0.004166118800640106, 0.05437684431672096, 0.029907166957855225, -0.02419106848537922, -0.006412559654563665, -0.015790367498993874, 0.03432344272732735, -0.03617448732256889, -0.011571832932531834, -0.010281872004270554, 0.028968075290322304, -0.020356381312012672, 0.10831866413354874, 0.019024964421987534, 0.08918300271034241, -0.01751677691936493, -0.009429104626178741, -0.024956852197647095, 0.03955018147826195, 0.0343017503619194, 0.046201933175325394, -0.0008523904834873974, 0.05269533023238182, -0.01136807817965746, 0.016333283856511116, 2.2003941069215216e-07, -0.06276096403598785, 0.034749239683151245, -0.0029351934790611267, -0.0322723351418972, 0.04128950834274292, -0.015801722183823586, -0.07346612960100174, -0.0037452271208167076, -0.019275758415460587, -0.023661687970161438, -0.01859692670404911, -0.041644930839538574, 0.051195379346609116, -0.042845360934734344, 0.01693210005760193, -0.061989787966012955, 0.04114117845892906, -0.042031072080135345, -0.0511065348982811, -0.032545533031225204, -0.018042130395770073, 0.004932831507176161, 0.030035190284252167, 0.032646145671606064, 0.006916569080203772, 0.00738536287099123, -0.0061651295982301235, -0.023101648315787315, -0.016280759125947952, 0.056980859488248825, -0.039373598992824554, 0.04363609105348587, 0.03515619784593582, -0.05637431889772415, -0.027522137388586998, -0.03875947743654251, 0.017885906621813774, 0.01980314962565899, -0.02721872180700302, 0.019144421443343163, -0.02037232741713524, 0.035730116069316864, 0.015754003077745438, 0.02078993059694767, -0.033679962158203125, 0.03708930313587189, -0.029874715954065323, -0.0038135501090437174, -0.023303329944610596, -0.036005619913339615, -0.008568047545850277, -0.025405600666999817, 0.029474753886461258, 0.028406130149960518, -0.0008482275297865272, -0.002838512882590294, 0.013656103052198887, 0.08280444890260696, 0.04106738045811653, -0.016987532377243042, -0.04080143943428993, -0.0023589525371789932, -0.04186870530247688, -0.045349664986133575, -0.035542577505111694, -0.016077399253845215, 0.00500451447442174, 1.6516290263890762e-34, -0.01422848179936409, -0.052669085562229156, -0.01730773225426674, -0.01810591109097004, 0.017301589250564575, -0.030699841678142548, 0.09678050875663757, -0.0008607468334957957, -0.06705863028764725, -0.01878543011844158, -0.004902007058262825]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "\n",
        "# Create a FAISS instance for vector database from 'data'\n",
        "vectordb = FAISS.from_documents(documents=all_splits,\n",
        "                                 embedding=embeddings)\n",
        "\n",
        "# Create a retriever for querying the vector database\n",
        "retriever = vectordb.as_retriever(score_threshold = 0.7)"
      ],
      "metadata": {
        "id": "6E2qslc8pEEM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdocs = retriever.get_relevant_documents(\"which api i used in this repo?\")\n",
        "rdocs"
      ],
      "metadata": {
        "id": "1J3ANaQhpFfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
        "# In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
        "# If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
        "\n",
        "# CONTEXT: {context}\n",
        "\n",
        "# QUESTION: {question}\"\"\"\n",
        "\n",
        "\n",
        "# PROMPT = PromptTemplate(\n",
        "#     template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "# )\n",
        "# chain_type_kwargs = {\"prompt\": PROMPT}"
      ],
      "metadata": {
        "id": "p92R7Is2BucI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# template for an instrution with no input\n",
        "# prompt = PromptTemplate(\n",
        "#     input_variables=[\"instruction\"],\n",
        "#     template=\"{instruction}\")\n",
        "\n",
        "# template for an instruction with input\n",
        "# prompt_with_context = PromptTemplate(\n",
        "#     input_variables=[\"instruction\", \"context\"],\n",
        "#     template=\"{instruction}\\n\\nInput:\\n{context}\")\n",
        "\n",
        "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
        "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
        "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
        "\n",
        "CONTEXT: {context}\n",
        "\n",
        "QUESTION: {question}\"\"\"\n",
        "\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# llm_chain = LLMChain(llm=hf_pipeline, prompt=prompt)\n",
        "llm_context_chain = LLMChain(llm=hf_pipeline, prompt=PROMPT)\n",
        "\n",
        "# from langchain.chains import RetrievalQA\n",
        "\n",
        "# chain = RetrievalQA.from_chain_type(llm=hf_pipeline,\n",
        "#                             chain_type=\"stuff\",\n",
        "#                             retriever=retriever,\n",
        "#                             input_key=\"query\",\n",
        "#                             return_source_documents=True,\n",
        "#                             chain_type_kwargs=chain_type_kwargs)"
      ],
      "metadata": {
        "id": "kFvXjAmGpFZ2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# context = \"\"\"George Washington (February 22, 1732[b] - December 14, 1799) was an American military officer, statesman,\n",
        "# and Founding Father who served as the first president of the United States from 1789 to 1797.\"\"\"\n",
        "context=data\n",
        "print(llm_context_chain.predict(question=\"which traffic module use this repo?\", context=context).lstrip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhPAf7vCBVNX",
        "outputId": "3babd23e-1e05-42ba-bc12-0251abf5250c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft.Maps.Traffic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain('which api i used in this repo?')"
      ],
      "metadata": {
        "id": "fsK_xRbaBODY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hT0BQJ0touvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.document_loaders import GitLoader\n",
        "\n",
        "# # e.g. loading only python files\n",
        "# loader = GitLoader(\n",
        "#    repo_path=\"/content/git_repo/test_repo2\",\n",
        "#     file_filter=lambda file_path: file_path.endswith(\".js\"),\n",
        "# )"
      ],
      "metadata": {
        "id": "QuXdCTPqousr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rdocs = retriever.get_relevant_documents(\"which api i used in this repo?\")\n",
        "# rdocs"
      ],
      "metadata": {
        "id": "5s2XZX5rouqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYv_rhDkslkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
        "# In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
        "# If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
        "\n",
        "# CONTEXT: {context}\n",
        "\n",
        "# QUESTION: {question}\"\"\"\n",
        "\n",
        "\n",
        "# PROMPT = PromptTemplate(\n",
        "#     template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "# )\n",
        "# chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "\n",
        "\n",
        "# from langchain.chains import RetrievalQA\n",
        "\n",
        "# chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "#                             chain_type=\"stuff\",\n",
        "#                             retriever=retriever,\n",
        "#                             input_key=\"query\",\n",
        "#                             return_source_documents=True,\n",
        "#                             chain_type_kwargs=chain_type_kwargs)"
      ],
      "metadata": {
        "id": "fJZmYGgtslah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwNpHSVTBTXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chain('which api i used in this repo?')"
      ],
      "metadata": {
        "id": "vOyqS5lYswYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}